# Volt XA 블루프린트

## 주권적 지능을 위한 상태 유지 운영체제

날짜: 2026/2/15
분류: AGPL v3.0 오픈소스

---

# 1. 개요

Volt는 지능을 상태 유지 운영체제로 다루는 인지 아키텍처다. 사고와 발화를 분리하고, 검증과 생성을 분리하며, 메모리와 연산을 소비자 하드웨어 위에서 분리한다.

**현재 AI의 다섯 가지 구조적 문제와 Volt의 해법:**

| 문제 | 해법 | 메커니즘 |
|---|---|---|
| 고정된 수명 (컨텍스트 윈도우) | 무제한 메모리 | 백그라운드 블리딩을 갖춘 3계층 저장소 |
| 사고/발화 혼합 | 침묵적 추론 | Tensor Frame 슬롯 위의 Root-Attend-Refine |
| 무상태성 | 영속적 스트랜드 | RAM에 스트랜드별로 조직된 Tensor Frame |
| 중앙 집중 의존 | 소비자 하드웨어 | GPU+CPU 분리, KV 캐시로부터 해방 |
| 동결된 지식 | 추론이 곧 학습 | 프레임 축적 + 통합 + 졸업 |

# 2. 설계 원칙

1. **사고 ≠ 발화.** 구조화된 잠재 공간에서의 연산; 언어는 출력 경계에서만.
2. **적응적 연산.** 반복 횟수는 문제 난이도에서 자연 발생하며, 프롬프팅에 의존하지 않음.
3. **검증 가능한 결론.** 수렴으로부터 확신 점수 산출; 고확신 출력은 감사 가능한 증명 체인을 수반.
4. **무한 메모리.** 작업 메모리는 작고, 접근 가능한 메모리는 사용과 함께 성장하며, 장기 메모리는 저장 용량에만 제한됨.
5. **구조적 안전.** 제약은 결정론적 CPU 코드로 구현. Omega Veto: 하드웨어 인터럽트, 우회 불가.
6. **주권적 지능.** 사용자 하드웨어, 사용자 소유 메모리. 클라우드 의존 없음.
7. **개방 생태계.** 표준화된 Rust 트레이트. 기여 증명을 통한 가치 분배.

**패러다임 전환:** 지능은 연산 문제가 아니라 데이터 관리 문제다. 제약이 대규모 GPU에서 데이터베이스 엔지니어링으로 이동한다.

# 3. 아키텍처

## 3.1 레이어

| 레이어 | 이름 | 기능 |
|---|---|---|
| 0 | 외부 세계 | 사용자, API, 센서, P2P 메시 |
| 1 | 입력 변환기 | 원시 입력 → Tensor Frame |
| 2 | LLL Tensor Frame 버스 | 모든 컴포넌트를 연결하는 구조화된 데이터 프로토콜 |
| 3 | GPU Soft Core | SDE 역학을 통한 신경 직관 (RAR 루프) |
| 4 | CPU Hard Core | 결정론적 논리: 도구, 증명, 안전 |
| 5 | VoltDB | 3계층 메모리, 인덱싱, GC |
| 6 | 출력 액션 코어 | Tensor Frame → 사람이 읽을 수 있는 출력 |
| 7 | 지속 학습 | 프레임 축적, 통합, 졸업 |
| 8 | Intelligence Commons | 지식/모듈 거래를 위한 탈블록체인 원장 |
| 9 | UI / 테스트 벤치 | 디버깅, 채팅, 워크플로우 오케스트레이션 |
| 10 | 소켓 표준 | Translator, HardStrand, ActionCore 트레이트 인터페이스 |

## 3.2 분할 뇌 하드웨어

**GPU (Soft Core):** 병렬 신경 연산 — 패턴 매칭, 에너지 지형 탐색, 확산 노이즈 탐색. RAR 루프로 작동.

**CPU (Hard Core):** 순차적 결정론적 논리 — 수학, 코드 실행, API 디스패치, 확신, 증명, 안전. 네이티브 Rust.

**RAM (VoltDB):** 영속 메모리 — 스트랜드에 수백만 개의 Tensor Frame, HNSW(의미), B-tree(시간), 역인덱스(개념)로 색인.

LLL Tensor Frame 버스로 상호 연결 — 평탄한 벡터나 토큰이 아닌 구조화된 프레임을 전달.

# 4. Tensor Frame

## 4.1 정의

F ∈ ℝ^[S × R × D] — 3차원 희소 텐서.

- **S = 16 슬롯:** AGENT, PREDICATE, PATIENT, LOCATION, TIME, MANNER, INSTRUMENT, CAUSE, RESULT, 7 FREE
- **R = 4 해상도:** R₀ 담화 → R₁ 명제 → R₂ 구 → R₃ 토큰
- **D = 256 차원** (슬롯당 해상도당)

최대: 64 KB. 일반적 희소: ~8 KB (4 슬롯 × 2 해상도).

평탄한 LLL 벡터는 하나의 슬롯, 하나의 해상도로 축소된 Tensor Frame이다 — 모든 HDC 대수(바인딩, 중첩, 순열)가 개별 슬롯 임베딩에서 여전히 작동한다. Tensor Frame은 엄밀한 일반화다.

## 4.2 해상도 매핑

| 레벨 | 내용 | 소비자 |
|---|---|---|
| R₀ 담화 | 주제, 분위기, 의도 | GPU Soft Core, Bleed Buffer |
| R₁ 명제 | 문장 수준 의미론 | GPU + CPU |
| R₂ 구 | 엔티티, 값, 수식어 | CPU, 출력 디코더 |
| R₃ 토큰 | 서브워드 토큰 | 출력 (디코드 전용) |

## 4.3 연산

- **슬롯 쓰기:** 랜덤 접근 — `F[slot=2, res=1] = encode("lifetime bug")`
- **해상도 줌:** R₀에서 추론, 필요한 곳에서만 R₂/R₃로 드릴다운
- **합성:** 비어있지 않은 슬롯 병합, γ 우선 충돌 해결, 정보 손실 없음
- **병렬 디코드:** 모든 슬롯 동시 처리; 5슬롯 = 1슬롯 벽시계 시간
- **희소 어텐션:** O(16²×256) = 65,536 연산; 100K 컨텍스트 트랜스포머 대비 ~2,000만 배 저렴

# 5. LLL 벡터 버스

## 5.1 연산 (HDC/HRR 파생)

| 연산 | 기능 | 구현 |
|---|---|---|
| 바인딩 (⊗) | 결합적 연관 | `IFFT(FFT(a) ⊙ FFT(b))`, O(D log D) |
| 중첩 (+) | 집합 결합 | `normalize(a + b + c)` |
| 순열 (ρ) | 시퀀스 인코딩 | 순환 시프트: `a + ρ(b) + ρ²(c)` |
| 언바인딩 (⊗⁻¹) | 구성 요소 검색 | 자기역: `x⁻¹_i = x_{(-i mod D)}` |
| 역할-필러 | 구조화된 지식 | `Σᵢ(role_i ⊗ filler_i)` |

## 5.2 코드북

65,536 (2¹⁶) 항목 × 256차원 단위 벡터 = ~67 MB 상주. u16 주소 지정, HNSW 색인, 연속 벡터 ↔ 이산 저장 간 브릿지. 클러스터링된 LLM 은닉 상태로 초기화, VQ-VAE 커밋먼트 손실 + EMA 중심 갱신으로 정제.

## 5.3 확신 전파

슬롯별 γ ∈ [0,1]. 최솟값 규칙: `γ(A→C) = min(γ(A→B), γ(B→C))`. 프레임 γ = min(모든 채워진 슬롯). 하나의 불확실한 슬롯이 전체 확신을 정직하게 낮춘다.

# 6. 입력 변환기

## 6.1 텍스트 변환기

동결된 인코더 백본 (~1-7B 파라미터, 예: Llama/Mistral/Qwen)이 문맥 임베딩을 생성 — 파라미터는 절대 수정되지 않으며, "지식 사전"으로 사용. 학습 가능한 Frame Projection Head (~50M 파라미터)가 LLM 은닉 상태를 Tensor Frame 슬롯에 매핑: 의미 역할 탐지 → 슬롯 할당 → R₀/R₁ 해상도 채우기 → HNSW 탐색을 통한 VQ-VAE 코드북 양자화.

## 6.2 커뮤니티 변환기

| 변환기 | 입력 → 프레임 매핑 |
|---|---|
| 비전 | 객체 → AGENT/PATIENT; 장면 → LOCATION; 동작 → PREDICATE |
| 오디오 | 전사 → 텍스트 파이프라인; 비음성 → MANNER/INSTRUMENT |
| 데이터 | 스키마 필드 → 슬롯; 집계 → R₀ |
| 센서 | 측정값 → PATIENT; 소스 → AGENT; 시간 → TIME |
| OS | 이벤트 → PREDICATE; 경로/PID → PATIENT |

Translator 트레이트를 구현하는 독립 Rust 크레이트. 트레이트 인트로스펙션을 통한 자동 발견.

# 7. GPU Soft Core — Root-Attend-Refine

시스템 1: 빠르고, 병렬적이며, 연상적이고, 창의적. 공유 벡터장 네트워크를 통한 Tensor Frame 슬롯의 연속 역학. 3단계 루프: Root-Attend-Refine (RAR).

## 7.1 RAR 루프

**Root (병렬):** 각 활성 슬롯이 독립적인 VFN 패스를 받음:
```
root_i = f_θ(S_i[R₀])                            # VFN: [256]→[256]
σ_i = σ_φ(S_i, convergence_rate_i, mirror_signal) # 적응적 노이즈
ΔS_i = root_i + σ_i × sample_orthogonal_to(root_i)
```
공유 가중치 (합성곱 필터와 유사). 에너지 지형: `f_θ = -∇E`. 확산 컨트롤러: 수렴됨 → σ≈0; 정체됨 → 높은 σ; 창의적 → 더 높은 기준선. 16개 슬롯 모두 당혹스러울 만큼 병렬.

**Attend (슬롯 간):** 슬롯 + 고스트 프레임 간 스케일드 내적 어텐션:
```
A_ij = softmax((W_Q·root_i · W_K·root_j) / √64)
context_i = Σ_j(A_ij × W_V·root_j) + α × ghost_attention_i
```
비용: 65,536 곱셈-덧셈. 무시할 수 있는 수준.

**Refine (갱신 + 수렴):**
```
S_i(t+1) = normalize(S_i(t) + dt_i × (ΔS_i + β × context_i))
if ‖S_i(t+1) − S_i(t)‖ < ε: 슬롯 동결, γ_i 계산
```
동결된 슬롯은 여전히 Attend에서 K/V로 기능. 점진적 수렴: 쉬운 슬롯이 먼저 동결, GPU 부하 비례 감소. 모두 수렴하거나 예산 소진 시 종료 (정직한 부분적 γ).

## 7.2 VFN 구성

| 구성 | 파라미터 | 아키텍처 | 대상 |
|---|---|---|---|
| Edge | 100M | 게이트 MLP (4 레이어) | 모바일 |
| Standard | 500M | FNO (8 레이어) | 소비자 PC |
| Research | 2B | FNO + 잔차 (16 레이어) | 워크스테이션 |

## 7.3 고스트 블리드 버퍼

VRAM에 ~1,000개 R₀ 고스트 (~1 MB). Attend 중 에너지 골 생성. 코사인 유사도 > 임계값 시 페이지 폴트 트리거 → RAM에서 전체 프레임 로드. 블리드 엔진(CPU)이 HNSW 쿼리를 통해 유의미한 R₀ 변경 시 갱신.

## 7.4 연산 비용

쿼리당 ~25M FLOPs (12회 반복). GPT-4 500토큰 응답: ~900T FLOPs. **~3,600만 배 적은 연산.**

# 8. CPU Hard Core

시스템 2: 순차적, 논리적, 결정론적. 동일 입력 → 동일 출력. 계산 작업에서 환각 없음.

## 8.1 의도 라우터

R₀ 요지와 스트랜드 능력 벡터의 코사인 유사도. 순수 벡터 기하 — JSON 없음, 문자열 매칭 없음, 도구 이름 환각 없음.

## 8.2 하드 스트랜드

| 스트랜드 | 기능 |
|---|---|
| MathEngine | 임의 정밀도 산술/대수/미적분 |
| CodeRunner | 샌드박스 Rust/Python/WASM (wasmtime) |
| APIDispatch | Tokio를 통한 병렬 HTTP (50+ 동시) |
| HDCAlgebra | FFT 바인딩/언바인딩/중첩 |
| CertaintyEngine | 최솟값 규칙 γ 전파 + 증명 검증 |
| ProofConstructor | 추론 흔적을 증명 단계로 |
| CausalSimulator | Pearl의 do-미적분, 결과 미리보기 |
| LedgerStrand | Intelligence Commons 인터페이스 |
| SleepLearner | Forward-Forward 통합 코디네이터 |
| MirrorModule | 자기 모니터링, 루프 탐지, 불확실성 추정 |

결과: Resolved (프레임 + 증명), NeedsMoreInfo, Delegated, 또는 Failed.

커뮤니티: HardStrand 트레이트 구현 → Rust 크레이트 게시 → 의도 라우터가 자동 발견.

## 8.3 안전 레이어

**공리적 가드:** 암호학적으로 서명된 불변식 (물리적 위해 금지, CSAM 금지, WMD 금지, 신원 사기 금지, AI 인정). 학습에 면역.

**전이 모니터:** 모든 F(t)→F(t+1)이 불변식 벡터에 대해 검사됨. 경고 → 확산 증가. 치명적 → Omega Veto.

**Omega Veto:** 하드웨어 인터럽트, 소프트웨어 우회 불가. 중단 → 동결 → 로깅 → 인간 승인 필요.

# 9. VoltDB

인지 메모리를 관리하는 임베디드 Rust 라이브러리 (별도 프로세스가 아님).

## 9.1 3계층

| 계층 | 위치 | 용량 | 접근 |
|---|---|---|---|
| T0 | GPU VRAM | 64 프레임 + 가중치 + 고스트 | 즉시 |
| T1 | 시스템 RAM | 8-32 GB, ~500K 프레임 | ~2ms |
| T2 | RAM + NVMe | 64-160+ GB, 수백만 압축 | ~10-50ms |

T0은 80%에서 퇴거: `score = w₁·최신성 + w₂·γ + w₃·log(참조수) + w₄·스트랜드_중요도 - w₅·대체됨`. R₀ 고스트는 블리드 버퍼에 유지.

T1: LSM-Tree (memtable → 정렬된 런 → 백그라운드 컴팩션).

T2: `mmap` 압축 아카이브, `rkyv` 제로카피 역직렬화.

## 9.2 인덱싱

스트랜드 라우팅 (HashMap, O(1)) → 스트랜드별 HNSW + B-tree + 역인덱스 (O(log N)) → 프레임 내부 O(1). 총: O(log N). 10M 프레임 ≈ 2.3ms. 블룸 필터로 O(1) 음성 검사 (99.9%).

## 9.3 블리드 엔진

| 프로세스 | 경로 | 지연시간 |
|---|---|---|
| 예측적 프리페치 | T1→T0 (새 프레임에 HNSW) | ~2ms |
| 온디맨드 회상 | T2→T1→T0 (고스트 페이지 폴트) | ~10-50ms |
| 백그라운드 통합 | T0→T1 (퇴거, 고스트 유지) | 논블로킹 |
| 수면 아카이빙 | T1→T2 (R₀ 압축, 지혜 증류) | T1 80% 시 |

## 9.4 가비지 컬렉션

Full (64KB) → Compressed (8KB, R₀+R₁) → Gist (1KB, R₀) → Tombstone (32B).

유지율: `w₁·exp(-age/30d) + w₂·γ + w₃·log(1+refs) + w₄·strand + w₅·distilled - w₆·contradictions - w₇·redundancy`. 불멸: γ=1.0, 높은 참조수, 또는 사용자 고정.

## 9.5 일관성

γ 우선이 모순을 이김. 대체된 프레임은 태그 + γ 페널티. 스트랜드 범위 진실 (활성 스트랜드가 검색을 결정). HDC 부정을 통한 백그라운드 모순 탐지기.

## 9.6 동시성

`crossbeam-epoch` RCU를 통한 MVCC (읽기 스레드는 절대 차단되지 않음). 스트랜드별 뮤텍스 (스트랜드 간 병렬 쓰기). 충돌 복구를 위한 스트랜드별 WAL.

## 9.7 용량

| 계층 | 전체 프레임 | 압축 | ~토큰 |
|---|---|---|---|
| T0 (8GB) | 125K | — | 6M |
| T1 (32GB) | 500K | 32M | 1.6B |
| T2 (128GB+1TB) | 17M | 1.1B | 58B |

총 ~58B 토큰. GPT-4 컨텍스트: 128K.

# 10. 출력 액션 코어

모든 슬롯 동시 디코드 (5슬롯 = 1슬롯 벽시계 시간). 슬롯 R₁이 독립적으로 디코드 → 역할 순서 + 담화 접속사로 조립. 자기회귀 대비: 500 토큰 = 500 직렬 패스.

| 코어 | 출력 | 메커니즘 |
|---|---|---|
| Text | 자연어 | 슬롯별 디코드 + 증명 주석 |
| Speech | 오디오 | 텍스트 → TTS |
| Image | 생성 이미지 | PATIENT/MANNER → 확산 |
| Motor | 로봇 명령 | ACTION/INSTRUMENT → 프리미티브 |
| n8n | 웹훅 | PREDICATE → n8n 디스패치 |
| Ledger | 네트워크 게시 | 프레임 → 서명된 P2P |

# 11. 지속 학습

**추론이 곧 학습이다.** 모든 추론 → 저장된 프레임 → 미래의 컨텍스트. 학습/추론 구분 없음.

**즉시 (ms):** RAM 스트랜드 쓰기. 망각 제로, 즉시 효과, 가중치 변경 없음.

**수면 (시간, 유휴):** CPU가 프레임을 클러스터링 → 증류 (50→3-5 지혜 프레임) → VFN에 Forward-Forward 가중치 갱신 (한 번에 한 레이어, ~1× 추론 VRAM). 에너지 지형 재형성: 새 어트랙터 형성, 미사용 어트랙터 평탄화.

**발달적 (일-월):** 스트랜드 졸업 (토픽 클러스터가 전용 스트랜드로 승격). 런타임 모듈 핫플러그, 트레이트 인트로스펙션을 통한 자동 발견.

# 12. Intelligence Commons

주권적 지능을 위한 신뢰 최소화 회계, 암호화폐가 아님.

**L0 로컬:** 추가 전용 머클 로그, Ed25519 신원, ZK 증명. 완전 오프라인.
**L1 P2P:** libp2p 가십, CRDT 동기화, IPFS 모듈 레지스트리, 암호화된 스트랜드 마켓플레이스.
**L2 결제:** DAG 마이크로페이먼트, 고γ 사실 앵커링, 출처, 이차 거버넌스.

**가치 흐름:** 지식 기여 → 모듈 마켓플레이스 → 사실 검증 → 스트랜드 거래 (ZK).

토큰 (VOLT): 프리마인 제로, 100% 획득. 연기 가능한 HardStrand로 구현.

# 13. UI / 테스트 벤치

**Phase 1:** n8n 워크플로우 — Chat Trigger → HTTP (`localhost:8080/api/think`) → Switch → Reply (γ, strand, proof) + 디버그 패널.

**미래:** Tauri 데스크톱 → 모바일 → IDE 통합.

# 14. 소켓 표준

세 개의 Rust 트레이트 = 생태계 경계 ("AI를 위한 AM5 소켓"):

```rust
pub trait Translator: Send + Sync {
    fn name(&self) -> &str;
    fn encode(&self, raw: &[u8], modality: Modality) -> TensorFrame;
    fn supported_modalities(&self) -> Vec<Modality>;
}

pub trait HardStrand: Send + Sync {
    fn id(&self) -> StrandId;
    fn name(&self) -> &str;
    fn capability_vector(&self) -> &[f32; 256];
    fn execute(&self, intent: &TensorFrame) -> StrandResult;
    fn can_handle(&self, intent: &TensorFrame) -> f32;
    fn learning_signal(&self) -> Option<LearningEvent>;
}

pub trait ActionCore: Send + Sync {
    fn name(&self) -> &str;
    fn decode(&self, frame: &TensorFrame) -> Output;
    fn supported_outputs(&self) -> Vec<OutputModality>;
}
```

하나의 인터페이스, 무한한 모듈. O(N+M) 비용. 트레이트 인트로스펙션을 통한 자동 발견, 재컴파일 불필요.

# 15. 안전 아키텍처

## 15.1 심층 방어

세 개의 레이어, 각각 위 레이어를 관통한 것을 포착:

1. **소프트 편향 (학습):** GPU 에너지 지형 그래디언트 — 유익한 것을 끌어당기고, 유해한 것을 밀어냄. 파인튜닝을 통해 조정 가능. 대다수 윤리적 고려를 처리.
2. **하드 제약 (코딩):** CPU 공리적 가드 — 결정론적, 암호학적으로 서명, 학습에 면역. (§8.3 참조)
3. **비상 정지 (하드웨어):** Omega Veto — 소프트웨어 우회 불가, 인간 승인 필요.

## 15.2 인과적 안전

CausalSimulator: 프레임 복제 → 개입 → Soft Core 전방 실행 → 안전 기준 대비 평가 → 실세계 실행 전 유해 결과 플래그/차단.

## 15.3 확신으로서의 안전

최솟값 규칙 γ가 과도하게 확신하는 유해 출력을 방지. 불확실한 구성 요소가 전체 확신을 정직하게 낮춤. γ=0.50은 권위적이 아닌, 불확실한 것으로 제시.